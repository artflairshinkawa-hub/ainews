import streamlit as st
import feedparser
import time
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime
import requests
import re
import base64
from urllib.parse import quote, urlparse

def setup_touch_icon(image_path="app_icon.png"):
    """Injects Apple Touch Icon using base64 encoding."""
    try:
        with open(image_path, "rb") as f:
            img_bytes = f.read()
        b64_img = base64.b64encode(img_bytes).decode('utf-8')
        # mime type detection (simple)
        mime = "image/png"
        
        st.markdown(
            f"""
            <link rel="apple-touch-icon" href="data:{mime};base64,{b64_img}">
            <link rel="icon" href="data:{mime};base64,{b64_img}">
            """,
            unsafe_allow_html=True
        )
    except Exception as e:
        pass # Fail silently if icon missing

# --- Setup & Config ---
st.set_page_config(page_title="AI News Pro", page_icon="ğŸŒ", layout="wide")
setup_touch_icon()

# --- Custom Theme & CSS ---
if 'theme' not in st.session_state:
    st.session_state.theme = 'Dark'
if 'bookmarks' not in st.session_state:
    st.session_state.bookmarks = []
if 'recommendation_keywords' not in st.session_state:
    # Load keywords from URL params if available
    params = st.query_params.get("keywords", "")
    st.session_state.recommendation_keywords = params.split(",") if params else []
if 'date_filter' not in st.session_state:
    st.session_state.date_filter = "ã™ã¹ã¦"

# --- Theme Configuration ---
theme_colors = {
    'Dark': {
        'bg': '#000000',
        'sidebar_bg': '#161617',
        'card_bg': '#000000',
        'text': '#ffffff',
        'sub_text': '#a1a1a6',
        'border': '#333336',
        'button_bg': '#1c1c1e',
        'button_text': '#ffffff',
        'accent': '#ffffff',
        'input_bg': '#1c1c1e',
        'shadow': 'none'
    },
    'Light': {
        'bg': '#ffffff',
        'sidebar_bg': '#f5f5f7',
        'card_bg': '#ffffff',
        'text': '#1d1d1f',
        'sub_text': '#6e6e73',
        'border': '#d2d2d7',
        'button_bg': '#f5f5f7',
        'button_text': '#1d1d1f',
        'accent': '#000000',
        'input_bg': '#ffffff',
        'shadow': 'none'
    }
}
c = theme_colors[st.session_state.theme]

# --- Helper Functions ---
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    cleantext = ' '.join(cleantext.split())
    return cleantext

def parse_summary(html_content):
    if not html_content: return "", ""
    soup = BeautifulSoup(html_content, "html.parser")
    img_tag = soup.find('img')
    img_src = img_tag['src'] if img_tag else ""
    text = clean_html(html_content)
    return text, img_src

def get_high_res_image_url(url):
    if not url: return ""
    if "bing.com/th" in url: return f"{url}&w=800&h=450&c=7&rs=1"
    return url

@st.cache_data(ttl=3600)
def fetch_og_image(url):
    if not url or url == "#": return ""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.content, 'html.parser')
        og = soup.find('meta', property='og:image')
        if og: return og.get('content')
    except: pass
    return ""

@st.cache_data(ttl=300)
def fetch_news(source, category_code, query_text):
    """Fetch and parse news from RSS feeds."""
    
    # --- Global Top Aggregation Logic ---
    if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
        # Sources to aggregate
        agg_sources = [
            ("Bing News", "HEADLINES"),
            ("Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", "HEADLINES"),
            ("ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", "HEADLINES"),
            ("Google News", "HEADLINES"),
            ("NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹", "HEADLINES")
        ]
        
        all_items = []
        # Reuse fetch_news for each source (recursive call but with different source arg)
        # To avoid infinite recursion, we hardcode source names that are NOT "âš¡ ç·åˆãƒˆãƒƒãƒ—"
        for src, cat in agg_sources:
            try:
                items = fetch_news(src, cat, "")
                all_items.extend(items)
            except:
                continue
        
        # Sort by published date (newest first)
        # Note: published is a string, assuming ISO format or similar sorts correctly roughly.
        # Ideally, should convert to datetime, but for now string sort might suffice if format is consistent "YYYY-MM-DD..."
        # Our parsing standardizes to YYYY-MM-DD HH:MM:SS
        all_items.sort(key=lambda x: x['published'], reverse=True)
        
        # Take top 10
        top_10 = all_items[:10]
        
        # Fetch images for top 10 if missing
        for item in top_10:
            if not item['img_src']:
                 # Check cache first
                ik = f"ic_{item['id']}"
                if ik in st.session_state:
                    item['img_src'] = st.session_state[ik]
                else:
                    # Fetch OG
                    try:
                        og_url = fetch_og_image(item['link'])
                        if og_url:
                            item['img_src'] = og_url
                            st.session_state[ik] = og_url # Cache it
                    except:
                        pass
        return top_10

    # --- Standard Source Logic ---
    url = ""
    if source == "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        # Using /categories/ for most to get 50 articles and fix "Life"
        mapping = {
            "HEADLINES": "topics/top-picks.xml",
            "TECHNOLOGY": "categories/it.xml",
            "BUSINESS": "categories/business.xml",
            "International": "categories/world.xml",
            "Entertainment": "categories/entertainment.xml",
            "Sports": "categories/sports.xml",
            "Science": "topics/science.xml", # No category for science
            "Local": "categories/local.xml",
            "Domestic": "categories/domestic.xml",
            "Life": "categories/life.xml"
        }
        url = f"https://news.yahoo.co.jp/rss/{mapping.get(category_code, 'topics/top-picks.xml')}"
    elif source == "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        mapping = {
            "HEADLINES": "cat0.xml", "Social": "cat1.xml", "Politics": "cat4.xml",
            "International": "cat6.xml", "Economy": "cat5.xml", "Science": "cat3.xml", "Sports": "cat2.xml",
            "Local": "cat9.xml"
        }
        url = f"https://www.nhk.or.jp/rss/news/{mapping.get(category_code, 'cat0.xml')}"
    elif source == "Bing News":
        q = query_text if category_code != "HEADLINES" else "ãƒˆãƒƒãƒ—ãƒ‹ãƒ¥ãƒ¼ã‚¹"
        url = f"https://www.bing.com/news/search?q={quote(q)}&format=rss&cc=JP&setLang=ja-JP"
    elif source == "Google News":
        # Mapping standard labels to working Google News Topic IDs
        g_map = {
            "HEADLINES": "", 
            "TECHNOLOGY": "TECHNOLOGY",
            "BUSINESS": "BUSINESS",
            "International": "WORLD",
            "Entertainment": "ENTERTAINMENT",
            "Sports": "SPORTS",
            "Science": "SCIENCE",
            "Health": "HEALTH"
        }
        params = "hl=ja&gl=JP&ceid=JP:ja"
        if category_code == "SEARCH": 
            url = f"https://news.google.com/rss/search?q={quote(query_text)}&{params}"
        elif category_code == "HEADLINES": 
            url = f"https://news.google.com/rss?{params}"
        else: 
            # Use the more stable /headlines/section/topic/ format
            topic_id = g_map.get(category_code, "")
            if topic_id:
                url = f"https://news.google.com/rss/headlines/section/topic/{topic_id}?{params}"
            else:
                url = f"https://news.google.com/rss?{params}"
    elif source == "Qiita":
        url = f"https://qiita.com/tags/{quote(query_text) if category_code != 'HEADLINES' else 'Python'}/feed"
    elif source == "Zenn":
        url = f"https://zenn.dev/topics/{quote(query_text.lower()) if category_code != 'HEADLINES' else 'tech'}/feed"
    elif source == "ITmedia":
        it_map = {
            "ALL": "itmedia_all.xml", "MOBILE": "mobile.xml", "ENTERPRISE": "enterprise.xml",
            "PCUSER": "pcuser.xml", "BUSINESS": "business.xml"
        }
        url = f"https://rss.itmedia.co.jp/rss/2.0/{it_map.get(category_code, 'itmedia_all.xml')}"
    elif source == "ãƒŠã‚¿ãƒªãƒ¼":
        natalie_map = {
            "MUSIC": "music", "MOVIE": "eiga", "COMEDY": "owarai", "COMIC": "comic"
        }
        category = natalie_map.get(category_code, "music")
        url = f"https://natalie.mu/{category}/feed/news"
    elif source == "CNET Japan":
        url = "https://japan.cnet.com/rss/index.rdf"
    elif source == "TechCrunch Japan":
        url = "https://techcrunch.com/tag/japan/feed/"
    elif source == "Gigazine":
        url = "https://gigazine.net/news/rss_2.0/"
    elif source == "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        url = "https://news.livedoor.com/topics/rss/top.xml"

    if not url: return []
    try:
        feed = feedparser.parse(url)
        processed = []
        for entry in feed.entries:
            title = entry.get('title', 'No Title')
            link = entry.get('link', '#')
            raw_sum = entry.get('summary', '') or entry.get('description', '') or entry.get('content', [{'value': ''}])[0].get('value', '')
            img = entry.get('news_image', '') or entry.get('media_thumbnail', [{'url':''}])[0].get('url','')
            if not img:
                 for enc in entry.get('enclosures', []):
                    if 'image' in enc.get('type', '') or any(ext in enc.get('href', '').lower() for ext in ['.jpg','.jpeg','.png','.webp']):
                        img = enc.get('href', '')
                        break
            summary_text, html_img = parse_summary(raw_sum)
            if not img: img = html_img
            processed.append({
                'title': title, 'link': link, 'summary': summary_text, 
                'img_src': get_high_res_image_url(img), 'source': source, 
                'id': link, 'published': entry.get('published', '')[:16]
            })
        return processed
    except: return []

def calculate_article_score(article, keywords):
    """Calculate relevance score for an article based on keywords and freshness."""
    if not keywords:
        return 0
    
    score = 0
    title_lower = article['title'].lower()
    summary_lower = article['summary'].lower()
    
    # Keyword matching (max 50 points)
    keyword_matched = False
    for keyword in keywords:
        kw_lower = keyword.lower()
        if kw_lower in title_lower:
            score += 30
            keyword_matched = True
        elif kw_lower in summary_lower:
            score += 20
            keyword_matched = True
    
    # Only add freshness bonus if at least one keyword matched
    if keyword_matched:
        score += 15  # Freshness bonus for relevant articles
    
    return score

def get_recommended_articles(keywords, max_articles=30):
    """Aggregate articles from all sources and score them."""
    if not keywords:
        return []
    
    # --- News Sources & Categories ---
    news_sources = [
        "âš¡ ç·åˆãƒˆãƒƒãƒ—",
        "Bing News",
        "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "Google News", 
        "Gigazine", 
        "ITmedia",
        "CNET Japan",
        "TechCrunch Japan",
        "Qiita",
        "Zenn",
        "ãƒŠã‚¿ãƒªãƒ¼"
    ]
    all_articles = []
    
    # Collect articles from all sources
    for source in news_sources:
        # Skip "âš¡ ç·åˆãƒˆãƒƒãƒ—" to avoid double fetching or complex logic here
        if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
            continue
        try:
            articles = fetch_news(source, "HEADLINES", "")
            for article in articles:
                article['source'] = source
            all_articles.extend(articles)
        except:
            continue
    
    # Score and filter articles
    scored_articles = []
    seen_titles = set()
    
    for article in all_articles:
        # Deduplicate by title
        if article['title'] in seen_titles:
            continue
        seen_titles.add(article['title'])
        
        score = calculate_article_score(article, keywords)
        if score > 0:
            scored_articles.append((score, article))
    
    # Sort by score and return top articles with scores
    scored_articles.sort(reverse=True, key=lambda x: x[0])
    return scored_articles[:max_articles]

def get_search_results(query):
    """Search for a keyword across multiple sources."""
    if not query: return []
    
    search_sources = [
        ("Bing News", "SEARCH"),
        ("Google News", "SEARCH"),
        ("Qiita", "SEARCH"),
        ("Zenn", "SEARCH")
    ]
    
    results = []
    seen_links = set()
    
    for source, cat_code in search_sources:
        try:
            articles = fetch_news(source, cat_code, query)
            for article in articles:
                if article['link'] not in seen_links:
                    results.append(article)
                    seen_links.add(article['link'])
        except:
            continue
            
    return results


# --- Design ---
st.markdown(f"""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
    
    html, body, [data-testid="stAppViewContainer"] {{
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
        background-color: {c['bg']};
    }}
    
    header[data-testid="stHeader"] svg {{
        fill: #888888 !important;
        opacity: 0.8;
    }}
    header[data-testid="stHeader"] button {{
        color: #888888 !important;
    }}
    header[data-testid="stHeader"] {{ background-color: transparent !important; }}
    
    /* Requested Header Background Fix */
    .st-emotion-cache-14vh5up {{
        background-color: {c['bg']} !important;
    }}
    
    [data-testid="stMain"] {{
        color: {c['text']} !important;
    }}

    [data-testid="stSidebar"] {{
        background-color: {c['sidebar_bg']} !important;
        border-right: 1px solid {c['border']};
    }}
    
    .sidebar-logo {{
        display: flex; align-items: center; gap: 14px;
        padding-bottom: 24px; margin-bottom: 32px;
        border-bottom: 1px solid {c['border']};
    }}
    .logo-text {{ font-size: 1.6rem; font-weight: 700; letter-spacing: -0.05em; color: {c['text']}; }}

    [data-testid="stSidebar"] section[data-testid="stSidebarNav"] span,
    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] p,
    [data-testid="stSidebar"] [data-testid="stWidgetLabel"] p,
    [data-testid="stSidebar"] label,
    [data-testid="stSidebar"] span,
    [data-testid="stSidebar"] div {{
        color: {c['text']} !important;
        font-weight: 600 !important;
    }}

    div[data-baseweb="select"] > div, div[data-baseweb="input"] > div {{
        background-color: {c['input_bg']} !important;
        border: 1px solid {c['border']} !important;
        border-radius: 8px !important;
    }}
    div[data-baseweb="select"] span, div[data-baseweb="input"] input,
    div[data-baseweb="select"] div[aria-selected="true"] {{
        color: {c['text']} !important;
        -webkit-text-fill-color: {c['text']} !important;
    }}

    .news-item {{
        padding: 24px 0;
        border-bottom: 1px solid {c['border']};
        margin-bottom: 8px;
    }}
    
    .news-title-link {{
        text-decoration: none !important;
        color: {c['text']} !important;
        transition: opacity 0.2s ease;
    }}
    .news-title-link:hover {{ opacity: 0.7; }}
    
    .news-title {{
        font-size: 1.35rem; font-weight: 700; line-height: 1.4; margin-bottom: 12px; color: {c['text']};
    }}
    
    .news-excerpt {{
        font-size: 0.95rem; color: {c['sub_text']} !important; line-height: 1.6; margin-bottom: 16px;
        display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden;
    }}
    
    .news-meta {{
        font-size: 0.85rem; color: {c['sub_text']} !important; font-weight: 500; text-transform: uppercase; letter-spacing: 0.03em; margin-bottom: 12px;
    }}
    
    img.news-thumb {{
        width: 100%; aspect-ratio: 16/9; object-fit: cover;
        border-radius: 12px;
        margin-bottom: 16px;
        background-color: {c['border']};
    }}
    
    .stButton > button {{
        background-color: {c['button_bg']} !important;
        color: {c['button_text']} !important;
        border: 1px solid {c['border']} !important;
        border-radius: 980px !important;
        font-weight: 600 !important;
        padding: 8px 16px !important;
        font-size: 0.9rem !important;
    }}
    .stButton > button:hover {{ background-color: {c['accent']} !important; color: {c['bg']} !important; }}

    .stTabs [data-baseweb="tab-list"] {{ gap: 40px; border-bottom: 1px solid {c['border']}; }}
    .stTabs [data-baseweb="tab"] {{ height: 60px; font-size: 1.2rem; color: {c['sub_text']}; font-weight: 700; }}
    .stTabs [aria-selected="true"] {{ color: {c['text']} !important; border-bottom-color: {c['text']} !important; }}
    
    .score-badge {{
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 0.85rem;
        font-weight: 600;
        margin-left: 8px;
        display: inline-block;
    }}
</style>
""", unsafe_allow_html=True)

# --- Sidebar ---
with st.sidebar:
    st.markdown(f"<h1 style='color: {c['text']}; display: flex; align-items: center; gap: 10px;'><span style='font-size: 1.5em;'>ğŸŒ</span> AI News Pro</h1>", unsafe_allow_html=True)
    
    st.markdown("### Settings")
    theme_btn = st.radio("ãƒ†ãƒ¼ãƒé¸æŠ", ["Dark", "Light"], horizontal=True, index=0 if st.session_state.theme == "Dark" else 1)
    if theme_btn != st.session_state.theme:
        st.session_state.theme = theme_btn
        st.rerun()

    # Define news sources
    news_sources = [
        "âš¡ ç·åˆãƒˆãƒƒãƒ—",
        "Bing News",
        "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "Google News", 
        "Gigazine", 
        "ITmedia",
        "CNET Japan",
        "TechCrunch Japan",
        "Qiita",
        "Zenn",
        "ãƒŠã‚¿ãƒªãƒ¼"
    ]

    source = st.selectbox(
        "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹", 
        news_sources, 
        index=0, # Set "âš¡ ç·åˆãƒˆãƒƒãƒ—" as default
        key="news_source_select"
    )
    
    cats = {}
    if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
        cats = {"æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰": "HEADLINES"}
    elif source == "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        cats = {
            "ä¸»è¦": "HEADLINES", "ITãƒ»ç§‘å­¦": "TECHNOLOGY", "çµŒæ¸ˆ": "BUSINESS", "å›½éš›": "International", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "å›½å†…": "Domestic", "ãƒ©ã‚¤ãƒ•": "Life", 
            "åœ°åŸŸ": "Local"
        }
    elif source == "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        cats = {
            "ä¸»è¦": "HEADLINES", "ç¤¾ä¼š": "Social", "æ”¿æ²»": "Politics", "å›½éš›": "International", 
            "çµŒæ¸ˆ": "Economy", "ç§‘å­¦ãƒ»æ–‡åŒ–": "Science", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "åœ°åŸŸ": "Local"
        }
    elif source == "Google News":
        cats = {
            "ãƒˆãƒƒãƒ—": "HEADLINES", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": "TECHNOLOGY", "ãƒ“ã‚¸ãƒã‚¹": "BUSINESS", "å›½éš›": "International", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "ç§‘å­¦": "Science", "å¥åº·": "Health"
        }
    elif source == "ITmedia":
        cats = {
            "ç·åˆ": "ALL", "ãƒ¢ãƒã‚¤ãƒ«": "MOBILE", "ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º": "ENTERPRISE", 
            "PC USER": "PCUSER", "ãƒ“ã‚¸ãƒã‚¹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³": "BUSINESS"
        }
    elif source in ["Qiita", "Zenn"]:
        cats = {"ãƒˆãƒ¬ãƒ³ãƒ‰": "HEADLINES"}
    elif source == "ãƒŠã‚¿ãƒªãƒ¼":
        cats = {
            "éŸ³æ¥½": "MUSIC", "æ˜ ç”»": "MOVIE", "ãŠç¬‘ã„": "COMEDY", "ã‚³ãƒŸãƒƒã‚¯": "COMIC"
        }
    elif source in ["CNET Japan", "TechCrunch Japan", "Gigazine", "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹"]:
        cats = {"ãƒˆãƒƒãƒ—": "HEADLINES"}
    elif source == "Bing News":
        cats = {
            "ãƒˆãƒƒãƒ—": "HEADLINES", "ãƒ“ã‚¸ãƒã‚¹": "Business", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": "Technology", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "æ”¿æ²»": "Politics", "ç§‘å­¦": "Science", 
            "å¥åº·": "Health", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "å›½éš›": "World", "å›½å†…": "Japan"
        }
        
    cat_label = st.selectbox("ã‚«ãƒ†ã‚´ãƒªãƒ¼", list(cats.keys()), key=f"cat_select_{source}")
    cat_code = cats[cat_label]
    # Query input removed from here as it moved to global search
    
    st.divider()
    
    # Date filter
    st.session_state.date_filter = st.selectbox(
        "è¡¨ç¤ºæœŸé–“", 
        ["ã™ã¹ã¦", "ä»Šæ—¥", "éå»3æ—¥", "éå»1é€±é–“"],
        index=["ã™ã¹ã¦", "ä»Šæ—¥", "éå»3æ—¥", "éå»1é€±é–“"].index(st.session_state.date_filter)
    )
    
    st.divider()
    st.markdown("### ãŠã™ã™ã‚è¨­å®š")
    
    # Keyword management with Enter key support
    def add_keyword():
        new_kw = st.session_state.new_keyword_input
        if new_kw and new_kw not in st.session_state.recommendation_keywords:
            if len(st.session_state.recommendation_keywords) < 5:
                st.session_state.recommendation_keywords.append(new_kw)
                st.session_state.new_keyword_input = ""  # Clear input
                # Update URL params
                st.query_params["keywords"] = ",".join(st.session_state.recommendation_keywords)
    
    new_keyword = st.text_input(
        "èˆˆå‘³ã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆEnterã§è¿½åŠ ï¼‰", 
        key="new_keyword_input", 
        placeholder="ä¾‹: AI, Python, çµŒæ¸ˆ",
        on_change=add_keyword
    )
    
    
    # Display current keywords
    if st.session_state.recommendation_keywords:
        st.markdown("**ç™»éŒ²æ¸ˆã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
        for i, kw in enumerate(st.session_state.recommendation_keywords):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"â€¢ {kw}")
            with col2:
                if st.button("âœ•", key=f"remove_kw_{i}", use_container_width=True):
                    st.session_state.recommendation_keywords.pop(i)
                    # Update URL params
                    st.query_params["keywords"] = ",".join(st.session_state.recommendation_keywords)
                    st.rerun()
    
    
    st.divider()

# --- Main Content ---
st.markdown(f"<h1>{source}</h1>", unsafe_allow_html=True)
st.markdown(f"<p style='color:{c['sub_text']}; font-size:1.3rem; font-weight:600; margin-top:-15px;'>{cat_label}</p>", unsafe_allow_html=True)

tab1, tab2, tab3, tab4 = st.tabs(["æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ãŠã™ã™ã‚", "ä¿å­˜æ¸ˆã¿", "æ¤œç´¢"])

with tab1:
    content_col = st.container()
    with content_col:
        c1, c2 = st.columns([1, 1])
        with c1: 
            if st.button("æ›´æ–°", use_container_width=True): st.rerun()
        with c2:
            if st.button("ğŸ–¼ï¸ å…¨ç”»åƒã‚’èª­ã¿è¾¼ã‚€", use_container_width=True):
                items = fetch_news(source, cat_code, "")
                for it in items:
                    ik = f"ic_{it['id']}"
                    if not it['img_src'] and ik not in st.session_state:
                        st.session_state[ik] = fetch_og_image(it['link'])
                st.rerun()

        with st.spinner("å–å¾—ä¸­..."):
            news_items = fetch_news(source, cat_code, "")
            
        if news_items:
            cols = st.columns(3)
            for i, item in enumerate(news_items):
                with cols[i % 3]:
                    st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                    ik = f"ic_{item['id']}"
                    img = item['img_src'] or st.session_state.get(ik)
                    
                    st.markdown(f'<div class="news-meta">{item["source"]} â€¢ {item["published"]}</div>', unsafe_allow_html=True)
                    if img: st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                    st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                    
                    if item['summary']:
                        st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                    
                    b1, b2 = st.columns(2)
                    with b1:
                        if not img:
                            if st.button("ğŸ–¼ï¸ ç”»åƒ", key=f"img_{i}", use_container_width=True):
                                st.session_state[ik] = fetch_og_image(item['link'])
                                st.rerun()
                    with b2:
                        if st.button("ä¿å­˜ ğŸ”–", key=f"sav_{i}", use_container_width=True):
                            if not any(b['link'] == item['link'] for b in st.session_state.bookmarks):
                                st.session_state.bookmarks.append(item)
                                st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
        else: st.info("ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

with tab2:
    if not st.session_state.recommendation_keywords:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒãŠã™ã™ã‚è¨­å®šã€ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.markdown(f"**ç™»éŒ²ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:** {', '.join(st.session_state.recommendation_keywords)}")
        
        # Sorting options
        sort_option = st.radio("ä¸¦ã³é †", ["ã‚¹ã‚³ã‚¢é †", "æ–°ã—ã„é †", "ã‚½ãƒ¼ã‚¹åˆ¥"], horizontal=True, key="rec_sort")
        
        with st.spinner("å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãŠã™ã™ã‚è¨˜äº‹ã‚’å–å¾—ä¸­..."):
            scored_items = get_recommended_articles(st.session_state.recommendation_keywords)
        
        if scored_items:
            # Apply sorting
            if sort_option == "æ–°ã—ã„é †":
                scored_items.sort(key=lambda x: x[1]['published'], reverse=True)
            elif sort_option == "ã‚½ãƒ¼ã‚¹åˆ¥":
                scored_items.sort(key=lambda x: x[1]['source'])
            # Default is already score order
            
            # Bulk image load button
            if st.button("ğŸ–¼ï¸ å…¨ç”»åƒã‚’èª­ã¿è¾¼ã‚€", key="rec_load_all_images", use_container_width=True):
                for score, item in scored_items:
                    ik = f"ic_{item['id']}"
                    if not item['img_src'] and ik not in st.session_state:
                        st.session_state[ik] = fetch_og_image(item['link'])
                st.rerun()
            
            cols = st.columns(3)
            for i, (score, item) in enumerate(scored_items):
                with cols[i % 3]:
                    st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                    ik = f"ic_{item['id']}"
                    img = item['img_src'] or st.session_state.get(ik)
                    
                    # Display source and score
                    st.markdown(
                        f'<div class="news-meta">{item["source"]} â€¢ {item["published"]}'
                        f'<span class="score-badge">ğŸ† {score}ç‚¹</span></div>', 
                        unsafe_allow_html=True
                    )
                    if img: st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                    st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                    
                    if item['summary']:
                        st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                    
                    if st.button("ä¿å­˜ ğŸ”–", key=f"rec_sav_{i}", use_container_width=True):
                        if not any(b['link'] == item['link'] for b in st.session_state.bookmarks):
                            st.session_state.bookmarks.append(item)
                            st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

with tab3:
    if not st.session_state.bookmarks:
        st.info("ä¿å­˜ã•ã‚ŒãŸè¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # CSV Export button
        if st.button("ğŸ“¥ CSVã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", use_container_width=True):
            df = pd.DataFrame([{
                'ã‚¿ã‚¤ãƒˆãƒ«': b['title'],
                'URL': b['link'],
                'ã‚½ãƒ¼ã‚¹': b['source'],
                'æ—¥ä»˜': b['published'],
                'è¦ç´„': b['summary']
            } for b in st.session_state.bookmarks])
            
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="bookmarks.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        st.divider()
        
        cols_b = st.columns(3)
        for i, item in enumerate(st.session_state.bookmarks):
            with cols_b[i % 3]:
                st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                ik = f"ic_{item['id']}"
                img = item.get('img_src') or st.session_state.get(ik)
                
                st.markdown(f'<div class="news-meta">{item["source"]} â€¢ {item["published"]}</div>', unsafe_allow_html=True)
                if img: st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                
                if item['summary']:
                    st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                
                if st.button("å‰Šé™¤ ğŸ—‘ï¸", key=f"del_{i}", use_container_width=True):
                    st.session_state.bookmarks.pop(i)
                    st.rerun()
                
                st.markdown('</div>', unsafe_allow_html=True)

with tab4:
    st.markdown("### å…¨ã‚½ãƒ¼ã‚¹æ¨ªæ–­æ¤œç´¢ ğŸ”")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        # Check date filter state for context
        filter_label = f" (æœŸé–“: {st.session_state.date_filter})" if st.session_state.date_filter != "ã™ã¹ã¦" else ""
        search_query = st.text_input(f"æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›{filter_label}", placeholder="ä¾‹: ç”ŸæˆAI, åŠå°ä½“, é¸æŒ™", key="global_search_input")
    with col2:
        st.markdown("<div style='margin-top: 28px;'></div>", unsafe_allow_html=True)
        search_btn = st.button("æ¤œç´¢", use_container_width=True, type="primary")
        
    if search_query:
        with st.spinner(f"'{search_query}' ã§å…¨ã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
            results = get_search_results(search_query)
            
            # Apply date filter
            filtered_results = []
            if st.session_state.date_filter != "ã™ã¹ã¦":
                now = datetime.now()
                for item in results:
                    try:
                        pub_date = pd.to_datetime(item['published'], utc=True).replace(tzinfo=None)
                        days_diff = (now - pub_date).days
                        if st.session_state.date_filter == "ä»Šæ—¥" and days_diff < 1:
                            filtered_results.append(item)
                        elif st.session_state.date_filter == "éå»3æ—¥" and days_diff < 3:
                            filtered_results.append(item)
                        elif st.session_state.date_filter == "éå»1é€±é–“" and days_diff < 7:
                            filtered_results.append(item)
                    except:
                        filtered_results.append(item)
            else:
                filtered_results = results

            st.markdown(f"**æ¤œç´¢çµæœ: {len(filtered_results)} ä»¶**")
            
            if not filtered_results:
                st.info("è©²å½“ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                cols = st.columns(3)
                for i, item in enumerate(filtered_results):
                    with cols[i % 3]:
                        # Helper to display card logic (reusing similar structure)
                        st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                        ik = f"sic_{i}_{item['link']}" # unique key
                        img = item.get('img_src')
                        
                        st.markdown(f'<div class="news-meta">{item["source"]} â€¢ {item["published"]}</div>', unsafe_allow_html=True)
                        if img: st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                        st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                        
                        if item['summary']:
                            st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                            
                        if st.button("ä¿å­˜ ğŸ”–", key=f"search_sav_{i}", use_container_width=True):
                            if not any(b['link'] == item['link'] for b in st.session_state.bookmarks):
                                st.session_state.bookmarks.append(item)
                                st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                        
                
                st.markdown('</div>', unsafe_allow_html=True)
