import streamlit as st
import streamlit.components.v1 as components
import feedparser
import time
import pandas as pd
from bs4 import BeautifulSoup
import datetime
import requests
import re
import base64
import difflib
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from urllib.parse import quote, urlparse
import random
import concurrent.futures
# Database module
import database as db

# --- Persistence & Auth Helpers ---
def get_remote_ip():
    """Get remote user IP from headers."""
    try:
        headers = st.context.headers
        for header in ["X-Forwarded-For", "X-Real-IP", "Remote-Addr"]:
            val = headers.get(header)
            if val:
                return val.split(",")[0].strip()
        return "0.0.0.0"
    except:
        return "0.0.0.0"

def reset_to_defaults():
    st.session_state.theme = 'Dark'
    st.session_state.bookmarks = []
    st.session_state.recommendation_keywords = []
    st.session_state.mute_words = []

def clear_auth_flow():
    st.session_state.auth_step = 'login'
    st.session_state.temp_email = None
    st.session_state.temp_secret = None

def logout():
    # Remove from DB if token exists in URL
    token = st.query_params.get('s')
    if token:
        db.delete_persistent_session(token)
    
    st.session_state.user = None
    st.session_state.guest_mode = False
    st.query_params.clear() # Clear URL params
    clear_auth_flow()
    reset_to_defaults()
    st.rerun()

def set_persistent_login(email, ip):
    """Create persistent session and set URL token."""
    token = db.create_persistent_session(email, ip)
    st.query_params['s'] = token # URL for bookmarking
    return token

# Initialize DB
db.init_db()

# Page Config

def setup_touch_icon():
    """Injects Apple Touch Icon using SVG emoji for Streamlit Cloud compatibility."""
    # Create SVG with banana emoji
    svg_icon = """
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100">
        <rect width="100" height="100" fill="#000000" rx="20"/>
        <text x="50" y="70" font-size="60" text-anchor="middle">ğŸŒ</text>
    </svg>
    """
    
    # Convert SVG to base64
    import base64
    b64_svg = base64.b64encode(svg_icon.encode('utf-8')).decode('utf-8')
    
    st.markdown(
        f"""
        <link rel="apple-touch-icon" sizes="180x180" href="data:image/svg+xml;base64,{b64_svg}">
        <link rel="apple-touch-icon" sizes="152x152" href="data:image/svg+xml;base64,{b64_svg}">
        <link rel="apple-touch-icon" sizes="120x120" href="data:image/svg+xml;base64,{b64_svg}">
        <link rel="apple-touch-icon" href="data:image/svg+xml;base64,{b64_svg}">
        <link rel="icon" type="image/svg+xml" href="data:image/svg+xml;base64,{b64_svg}">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
        <meta name="apple-mobile-web-app-title" content="AI News Pro">
        """,
        unsafe_allow_html=True
    )

# --- Setup & Config ---
st.set_page_config(page_title="AI News Pro", page_icon="ğŸŒ", layout="wide")
setup_touch_icon()

ALL_SOURCES = [
    "Bing News", "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
    "Google News", "Gigazine", "ITmedia", "CNET Japan", 
    "TechCrunch Japan", "Qiita", "Zenn", "ãƒŠã‚¿ãƒªãƒ¼"
]

# Logic to load user data if logged in
def load_user_session():
    if st.session_state.user:
        username = st.session_state.user
        st.session_state.recommendation_keywords = db.load_user_data(username, 'keywords', [])
        st.session_state.bookmarks = db.load_user_data(username, 'bookmarks', [])
        saved_theme = db.load_user_data(username, 'theme', 'Dark')
        st.session_state.theme = saved_theme
        st.session_state.mute_words = db.load_user_data(username, 'mute_words', [])

if 'theme' not in st.session_state:
    st.session_state.theme = 'Dark'
if 'bookmarks' not in st.session_state:
    st.session_state.bookmarks = []
if 'recommendation_keywords' not in st.session_state:
    st.session_state.recommendation_keywords = []
if 'date_filter' not in st.session_state:
    st.session_state.date_filter = "ã™ã¹ã¦"
if 'mute_words' not in st.session_state:
    st.session_state.mute_words = []

# --- Session State & URL Persistence ---
if 'user' not in st.session_state:
    st.session_state.user = None

# Load persistent session from URL only
if st.session_state.user is None:
    token = st.query_params.get('s')
    if token:
        ip = get_remote_ip()
        result = db.verify_persistent_session(token, ip)
        if "@" in str(result):
            st.session_state.user = result
            load_user_session()
        else:
            # Token invalid/expired, clear it
            st.query_params.clear()

# Call load_user_session for normal session state sync
load_user_session()

# --- Theme Configuration ---
theme_colors = {
    'Dark': {
        'bg': '#000000',
        'sidebar_bg': '#161617',
        'card_bg': '#000000',
        'text': '#ffffff',
        'sub_text': '#a1a1a6',
        'border': '#333336',
        'button_bg': '#1c1c1e',
        'button_text': '#ffffff',
        'accent': '#ffffff',
        'input_bg': '#1c1c1e',
        'shadow': 'none'
    },
    'Light': {
        'bg': '#ffffff',
        'sidebar_bg': '#f5f5f7',
        'card_bg': '#ffffff',
        'text': '#1d1d1f',
        'sub_text': '#6e6e73',
        'border': '#d2d2d7',
        'button_bg': '#f5f5f7',
        'button_text': '#1d1d1f',
        'accent': '#000000',
        'input_bg': '#ffffff',
        'shadow': 'none'
    }
}
c = theme_colors[st.session_state.theme]

# --- Helper Functions ---
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    cleantext = ' '.join(cleantext.split())
    return cleantext

def parse_summary(html_content):
    if not html_content: return "", ""
    soup = BeautifulSoup(html_content, "html.parser")
    img_tag = soup.find('img')
    img_src = img_tag['src'] if img_tag else ""
    text = clean_html(html_content)
    return text, img_src

def get_high_res_image_url(url):
    if not url: return ""
    if "bing.com/th" in url: return f"{url}&w=800&h=450&c=7&rs=1"
    return url

@st.cache_data(ttl=3600)
def fetch_og_image(url):
    if not url or url == "#": return ""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.content, 'html.parser')
        og = soup.find('meta', property='og:image')
        if og: return og.get('content')
    except: pass
    return ""

def send_auth_email(target_email, subject, body):
    """Send an authentication email using Sakura Server SMTP."""
    # Check if SMTP secrets are configured
    if 'smtp' not in st.secrets:
        st.error("SMTPè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`st.secrets` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return False
    
    try:
        conf = st.secrets['smtp']
        smtp_server = conf['host']
        smtp_port = conf['port']
        sender_email = conf['user']
        sender_password = conf['password']
        
        # Create message
        msg = MIMEMultipart()
        msg['From'] = sender_email # Simplified to avoid rejection
        msg['To'] = target_email
        msg['Subject'] = subject
        
        msg.attach(MIMEText(body, 'plain'))
        
        # Connect and send
        server = smtplib.SMTP(smtp_server, smtp_port, timeout=10)
        server.starttls()
        server.login(sender_email, sender_password)
        # Explicitly specify envelope addresses
        server.send_message(msg, from_addr=sender_email, to_addrs=[target_email])
        server.quit()
        return True
    except Exception as e:
        if "5.7.1" in str(e):
             st.error(f"ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼ (5.7.1): ã•ãã‚‰ã‚µãƒ¼ãƒãƒ¼ã®ã€Œå›½å¤–IPã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ãŒæœ‰åŠ¹ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«ã‹ã‚‰è§£é™¤ã—ã¦ãã ã•ã„ã€‚")
        else:
             st.error(f"ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


def get_remote_ip():
    """Get remote user IP from headers."""
    try:
        # Check various headers for IP
        headers = st.context.headers
        for header in ["X-Forwarded-For", "X-Real-IP", "Remote-Addr"]:
            val = headers.get(header)
            if val:
                return val.split(",")[0].strip()
        return "0.0.0.0"
    except:
        return "0.0.0.0"

# --- Sidebar (Moved up for visibility during login) ---
with st.sidebar:
    st.markdown(f"<h1 style='color: {c['text']}; display: flex; align-items: center; gap: 10px;'><span style='font-size: 1.5em;'>ğŸŒ</span> AI News Pro</h1>", unsafe_allow_html=True)
    
    if st.session_state.user:
        st.caption(f"Logged in: {st.session_state.user}")
        if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", use_container_width=True):
            logout()
            st.rerun()
    else:
        st.caption("Guest Mode")
        st.info("ã‚²ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯è¨­å®šã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“")
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³ / ç™»éŒ²", use_container_width=True):
            st.session_state.guest_mode = False
            st.rerun()

    # --- Bookmark Info (Visible when logged in) ---
    if st.session_state.user:
        current_token = st.query_params.get('s')
        if current_token:
            with st.expander("ç¶™ç¶šãƒ­ã‚°ã‚¤ãƒ³ã®è¨­å®š", expanded=False):
                st.write("ã“ã®ãƒšãƒ¼ã‚¸ã‚’**ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ï¼ˆãŠæ°—ã«å…¥ã‚Šç™»éŒ²ï¼‰**ã—ã¦ãŠãã¨ã€æ¬¡å›ã‹ã‚‰è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ã•ã‚Œã¾ã™ã€‚")
                st.code(f"https://ainews-kdzbuhnlquqbapw9wj9yxh.streamlit.app/?s={current_token}")


    st.markdown("### Settings")
    theme_btn = st.radio("ãƒ†ãƒ¼ãƒé¸æŠ", ["Dark", "Light"], horizontal=True, index=0 if st.session_state.theme == "Dark" else 1)
    if theme_btn != st.session_state.theme:
        st.session_state.theme = theme_btn
        # Save theme setting
        if st.session_state.user:
            db.save_user_data(st.session_state.user, 'theme', theme_btn)
        st.rerun()

    st.divider()

    # Mute Settings
    with st.expander("ãƒŸãƒ¥ãƒ¼ãƒˆè¨­å®š"):
        st.caption("æŒ‡å®šã—ãŸå˜èªã‚’å«ã‚€è¨˜äº‹ã‚’éè¡¨ç¤ºã«ã—ã¾ã™")
        def add_mute():
            new_m = st.session_state.new_mute_input
            if new_m and new_m not in st.session_state.mute_words:
                st.session_state.mute_words.append(new_m)
                st.session_state.new_mute_input = ""
                if st.session_state.user:
                    db.save_user_data(st.session_state.user, 'mute_words', st.session_state.mute_words)
        
        st.text_input("é™¤å¤–ã—ãŸã„å˜èª", key="new_mute_input", on_change=add_mute)
        
        if st.session_state.mute_words:
            st.markdown("---")
            for i, mw in enumerate(st.session_state.mute_words):
                col1, col2 = st.columns([3, 1])
                col1.markdown(f"ğŸš« {mw}")
                if col2.button("âœ•", key=f"del_mute_{i}", use_container_width=True):
                    st.session_state.mute_words.pop(i)
                    if st.session_state.user:
                        db.save_user_data(st.session_state.user, 'mute_words', st.session_state.mute_words)
                    st.rerun()

    # Define news sources
    news_sources = [
        "âš¡ ç·åˆãƒˆãƒƒãƒ—",
        "Bing News",
        "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", 
        "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "Google News", 
        "Gigazine", 
        "ITmedia",
        "CNET Japan",
        "TechCrunch Japan",
        "Qiita",
        "Zenn",
        "ãƒŠã‚¿ãƒªãƒ¼"
    ]

    source = st.selectbox(
        "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹", 
        news_sources, 
        index=0, # Set "âš¡ ç·åˆãƒˆãƒƒãƒ—" as default
        key="news_source_select"
    )

    cats = {}
    if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
        cats = {"æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰": "HEADLINES"}
    elif source == "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        cats = {
            "ä¸»è¦": "HEADLINES", "ITãƒ»ç§‘å­¦": "TECHNOLOGY", "çµŒæ¸ˆ": "BUSINESS", "å›½éš›": "International", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "å›½å†…": "Domestic", "ãƒ©ã‚¤ãƒ•": "Life", 
            "åœ°åŸŸ": "Local"
        }
    elif source == "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        cats = {
            "ä¸»è¦": "HEADLINES", "ç¤¾ä¼š": "Social", "æ”¿æ²»": "Politics", "å›½éš›": "International", 
            "çµŒæ¸ˆ": "Economy", "ç§‘å­¦ãƒ»æ–‡åŒ–": "Science", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "åœ°åŸŸ": "Local"
        }
    elif source == "Google News":
        cats = {
            "ãƒˆãƒƒãƒ—": "HEADLINES", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": "TECHNOLOGY", "ãƒ“ã‚¸ãƒã‚¹": "BUSINESS", "å›½éš›": "International", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "ç§‘å­¦": "Science", "å¥åº·": "Health"
        }
    elif source == "ITmedia":
        cats = {
            "ç·åˆ": "ALL", "ãƒ¢ãƒã‚¤ãƒ«": "MOBILE", "ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º": "ENTERPRISE", 
            "PC USER": "PCUSER", "ãƒ“ã‚¸ãƒã‚¹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³": "BUSINESS"
        }
    elif source in ["Qiita", "Zenn"]:
        cats = {"ãƒˆãƒ¬ãƒ³ãƒ‰": "HEADLINES"}
    elif source == "ãƒŠã‚¿ãƒªãƒ¼":
        cats = {
            "éŸ³æ¥½": "MUSIC", "æ˜ ç”»": "MOVIE", "ãŠç¬‘ã„": "COMEDY", "ã‚³ãƒŸãƒƒã‚¯": "COMIC"
        }
    elif source in ["CNET Japan", "TechCrunch Japan", "Gigazine", "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹"]:
        cats = {"ãƒˆãƒƒãƒ—": "HEADLINES"}
    elif source == "Bing News":
        cats = {
            "ãƒˆãƒƒãƒ—": "HEADLINES", "ãƒ“ã‚¸ãƒã‚¹": "Business", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": "Technology", 
            "ã‚¨ãƒ³ã‚¿ãƒ¡": "Entertainment", "æ”¿æ²»": "Politics", "ç§‘å­¦": "Science", 
            "å¥åº·": "Health", "ã‚¹ãƒãƒ¼ãƒ„": "Sports", "å›½éš›": "World", "å›½å†…": "Japan"
        }
        
    cat_label = st.selectbox("ã‚«ãƒ†ã‚´ãƒªãƒ¼", list(cats.keys()), key=f"cat_select_{source}")
    cat_code = cats[cat_label]

    st.divider()
    st.markdown("### ãŠã™ã™ã‚è¨­å®š")

    # Keyword management with Enter key support
    def add_keyword():
        new_kw = st.session_state.new_keyword_input
        if new_kw and new_kw not in st.session_state.recommendation_keywords:
                if len(st.session_state.recommendation_keywords) < 5:
                    st.session_state.recommendation_keywords.append(new_kw)
                    st.session_state.new_keyword_input = ""  # Clear input
                    # Save to DB
                    if st.session_state.user:
                        db.save_user_data(st.session_state.user, 'keywords', st.session_state.recommendation_keywords)
                else:
                    st.warning("ç™»éŒ²ã§ãã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯5ã¤ã¾ã§ã§ã™")
        elif new_kw in st.session_state.recommendation_keywords:
            st.warning("ãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™")
    
    # Debug Options
    debug_mode = st.checkbox("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", key="debug_mode", help="ãŠã™ã™ã‚è¨˜äº‹ã®å–å¾—çŠ¶æ³ã‚’è¡¨ç¤ºã—ã¾ã™")

    new_keyword = st.text_input(
        "èˆˆå‘³ã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆEnterã§è¿½åŠ ï¼‰", 
        key="new_keyword_input", 
        placeholder="ä¾‹: AI, Python, çµŒæ¸ˆ",
        on_change=add_keyword
    )

    # Display current keywords
    if st.session_state.recommendation_keywords:
        st.markdown("**ç™»éŒ²æ¸ˆã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
        for i, kw in enumerate(st.session_state.recommendation_keywords):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"â€¢ {kw}")
            with col2:
                if st.button("âœ•", key=f"remove_kw_{i}", use_container_width=True):
                    st.session_state.recommendation_keywords.pop(i)
                    # Save to DB
                    if st.session_state.user:
                        db.save_user_data(st.session_state.user, 'keywords', st.session_state.recommendation_keywords)
                    st.rerun()

@st.cache_data(ttl=299)
def fetch_news(source, category_code, query_text):
    """Fetch and parse news from RSS feeds."""
    
    # Debug info (only visible if debug_mode is active in session)
    is_debug = st.session_state.get('debug_mode', False)
    
    # --- Global Top Aggregation Logic ---
    # --- Global Top Aggregation Logic ---
    if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
        # Aggregate from EVERY available source with BALANCED sampling
        source_configs = {
            "Bing News": "HEADLINES",
            "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹": "HEADLINES",
            "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹": "HEADLINES",
            "Google News": "HEADLINES",
            "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹": "HEADLINES",
            "Gigazine": "HEADLINES",
            "ITmedia": "ALL",
            "CNET Japan": "HEADLINES",
            "TechCrunch Japan": "HEADLINES",
            "Qiita": "HEADLINES",
            "Zenn": "HEADLINES",
            "ãƒŠã‚¿ãƒªãƒ¼": "MUSIC"
        }
        
        all_items = []
        seen_links = set()
        ARTICLES_PER_SOURCE = 5
        
        # Parallel Fetching
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_source = {
                executor.submit(fetch_news, src, cat, ""): src 
                for src, cat in source_configs.items()
            }
            
            for future in concurrent.futures.as_completed(future_to_source):
                try:
                    items = future.result()
                    # Take only first N items from each source
                    for item in items[:ARTICLES_PER_SOURCE]:
                        if item['link'] not in seen_links:
                            all_items.append(item)
                            seen_links.add(item['link'])
                except Exception as e:
                    if is_debug: print(f"Error fetching source in Global Top: {e}")
                    continue
        
        # Sort by published date (newest first)
        all_items.sort(key=lambda x: x['published'], reverse=True)
        
        # Return balanced mix (60 articles = 12 sources Ã— 5 each)
        return all_items[:60]

    # --- Standard Source Logic ---
    url = ""
    if source == "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        # Using /categories/ for most to get 50 articles and fix "Life"
        mapping = {
            "HEADLINES": "topics/top-picks.xml",
            "TECHNOLOGY": "categories/it.xml",
            "BUSINESS": "categories/business.xml",
            "International": "categories/world.xml",
            "Entertainment": "categories/entertainment.xml",
            "Sports": "categories/sports.xml",
            "Science": "topics/science.xml", # No category for science
            "Local": "categories/local.xml",
            "Domestic": "categories/domestic.xml",
            "Life": "categories/life.xml"
        }
        url = f"https://news.yahoo.co.jp/rss/{mapping.get(category_code, 'topics/top-picks.xml')}"
    elif source == "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        mapping = {
            "HEADLINES": "cat0.xml", "Social": "cat1.xml", "Politics": "cat4.xml",
            "International": "cat6.xml", "Economy": "cat5.xml", "Science": "cat3.xml", "Sports": "cat2.xml",
            "Local": "cat9.xml"
        }
        url = f"https://www.nhk.or.jp/rss/news/{mapping.get(category_code, 'cat0.xml')}"
    elif source == "Bing News":
        # Map category codes to Japanese search terms
        bing_map = {
            "HEADLINES": "ãƒˆãƒƒãƒ—ãƒ‹ãƒ¥ãƒ¼ã‚¹", "Business": "çµŒæ¸ˆ", "Technology": "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼",
            "Entertainment": "å·¥ãƒ³ã‚¿ãƒ¡", "Politics": "æ”¿æ²»", "Science": "ç§‘å­¦",
            "Health": "å¥åº·", "Sports": "ã‚¹ãƒãƒ¼ãƒ„", "World": "å›½éš›", "Japan": "å›½å†…ãƒˆãƒƒãƒ—"
        }
        # Use query_text if provided (global search), otherwise use category mapping
        q = query_text if query_text else bing_map.get(category_code, "ãƒˆãƒƒãƒ—ãƒ‹ãƒ¥ãƒ¼ã‚¹")
        url = f"https://www.bing.com/news/search?q={quote(q)}&format=rss&cc=JP&setLang=ja-JP"
    elif source == "Google News":
        # Mapping standard labels to working Google News Topic IDs
        g_map = {
            "HEADLINES": "", 
            "TECHNOLOGY": "TECHNOLOGY",
            "BUSINESS": "BUSINESS",
            "International": "WORLD",
            "Entertainment": "ENTERTAINMENT",
            "Sports": "SPORTS",
            "Science": "SCIENCE",
            "Health": "HEALTH"
        }
        params = "hl=ja&gl=JP&ceid=JP:ja"
        if category_code == "SEARCH": 
            url = f"https://news.google.com/rss/search?q={quote(query_text)}&{params}"
        elif category_code == "HEADLINES": 
            url = f"https://news.google.com/rss?{params}"
        else: 
            # Use the more stable /headlines/section/topic/ format
            topic_id = g_map.get(category_code, "")
            if topic_id:
                url = f"https://news.google.com/rss/headlines/section/topic/{topic_id}?{params}"
            else:
                url = f"https://news.google.com/rss?{params}"
    elif source == "Qiita":
        url = f"https://qiita.com/tags/{quote(query_text) if category_code == 'SEARCH' else 'Python'}/feed"
    elif source == "Zenn":
        url = f"https://zenn.dev/topics/{quote(query_text.lower()) if category_code == 'SEARCH' else 'tech'}/feed"
    elif source == "ITmedia":
        it_map = {
            "ALL": "itmedia_all.xml", "MOBILE": "mobile.xml", "ENTERPRISE": "enterprise.xml",
            "PCUSER": "pcuser.xml", "BUSINESS": "business.xml"
        }
        url = f"https://rss.itmedia.co.jp/rss/2.0/{it_map.get(category_code, 'itmedia_all.xml')}"
    elif source == "ãƒŠã‚¿ãƒªãƒ¼":
        natalie_map = {
            "MUSIC": "music", "MOVIE": "eiga", "COMEDY": "owarai", "COMIC": "comic"
        }
        category = natalie_map.get(category_code, "music")
        url = f"https://natalie.mu/{category}/feed/news"
    elif source == "CNET Japan":
        url = "https://japan.cnet.com/rss/index.rdf"
    elif source == "TechCrunch Japan":
        url = "https://techcrunch.com/tag/japan/feed/"
    elif source == "Gigazine":
        url = "https://gigazine.net/news/rss_2.0/"
    elif source == "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹":
        url = "https://news.livedoor.com/topics/rss/top.xml"

    if not url: return []
    try:
        # Use requests with User-Agent to avoid 403 Forbidden from some sites (Qiita, Zenn, etc.)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        feed = feedparser.parse(response.content)
        
        processed = []
        for entry in feed.entries:
            title = entry.get('title', 'No Title')
            link = entry.get('link', '#')
            raw_sum = entry.get('summary', '') or entry.get('description', '') or entry.get('content', [{'value': ''}])[0].get('value', '')
            img = entry.get('news_image', '') or entry.get('media_thumbnail', [{'url':''}])[0].get('url','')
            if not img:
                 for enc in entry.get('enclosures', []):
                    if 'image' in enc.get('type', '') or any(ext in enc.get('href', '').lower() for ext in ['.jpg','.jpeg','.png','.webp']):
                        img = enc.get('href', '')
                        break
            summary_text, html_img = parse_summary(raw_sum)
            if not img: img = html_img
            # Parse date for reliable sorting
            pub_date_raw = entry.get('published', '')
            pub_date_formatted = pub_date_raw[:16] # Fallback
            if 'published_parsed' in entry and entry.published_parsed:
                try:
                    dt = datetime(*entry.published_parsed[:6])
                    pub_date_formatted = dt.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    pass

            processed.append({
                'title': title, 'link': link, 'summary': summary_text, 
                'img_src': get_high_res_image_url(img), 'source': source, 
                'id': link, 'published': pub_date_formatted
            })
        return processed
    except: return []

def calculate_article_score(article, keywords):
    """Calculate relevance score for an article based on keywords and freshness."""
    if not keywords:
        return 0
    
    score = 0
    title_lower = article['title'].lower()
    summary_lower = article['summary'].lower()
    
    # Keyword matching (max 50 points)
    keyword_matched = False
    for keyword in keywords:
        kw_lower = keyword.lower()
        if kw_lower in title_lower:
            score += 30
            keyword_matched = True
        elif kw_lower in summary_lower:
            score += 20
            keyword_matched = True
    
    # Only add freshness bonus if at least one keyword matched
    if keyword_matched:
        score += 15  # Freshness bonus for relevant articles
    
    return score

def get_recommended_articles(keywords):
    """
    Fetch articles by actively searching for each keyword in ALL available sources.
    This ensures maximum recall even if it takes a bit longer.
    """
    if not keywords:
        return []
    
    # Debug info
    is_debug = st.session_state.get('debug_mode', False)
    
    all_articles = []
    seen_links = set()
    
    # Sources that rely on active searching
    search_driven_sources = ["Bing News", "Google News", "Qiita", "Zenn"]
    
    # Sources that rely on filtering recent headlines
    feed_driven_sources = [
        "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹", "NHK ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "Gigazine", "ITmedia", "CNET Japan", "TechCrunch Japan", "ãƒŠã‚¿ãƒªãƒ¼"
    ]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        
        # 1. Search Driven Sources (High Precision)
        for kw in keywords:
            for source in search_driven_sources:
                futures.append(executor.submit(fetch_news, source, "SEARCH", kw))

        # 2. Feed Driven Sources (Filter recent items)
        # For feeds, we just fetch once per source, then filter by all keywords locally
        for source in feed_driven_sources:
            cat_code = "HEADLINES"
            if source == "ITmedia": cat_code = "ALL"
            elif source == "ãƒŠã‚¿ãƒªãƒ¼": cat_code = "MUSIC"
            futures.append(executor.submit(fetch_news, source, cat_code, ""))
            
        for future in concurrent.futures.as_completed(futures):
            try:
                items = future.result()
                for item in items:
                    if item['link'] not in seen_links:
                        # Score calculation is fast, do it here
                        score = calculate_article_score(item, keywords)
                        if score > 0:
                            all_articles.append((score, item))
                            seen_links.add(item['link'])
            except Exception as e:
                if is_debug: print(f"Error in recommendation fetch: {e}")
                continue
                
    # Sort by score (descending)
    all_articles.sort(reverse=True, key=lambda x: x[0])
    
    if is_debug:
        st.write(f"Total articles found: {len(all_articles)}")
    
    # Return ALL items (filtering happens in UI)
    return all_articles

def get_search_results(query):
    """Search for a keyword across multiple sources."""
    if not query: return []
    
    search_sources = [
        ("Bing News", "SEARCH"),
        ("Google News", "SEARCH"),
        ("Qiita", "SEARCH"),
        ("Zenn", "SEARCH")
    ]
    
    results = []
    seen_links = set()
    
    for source, cat_code in search_sources:
        try:
            articles = fetch_news(source, cat_code, query)
            for article in articles:
                if article['link'] not in seen_links:
                    results.append(article)
                    seen_links.add(article['link'])
        except:
            continue
            
    return results

# --- Content Optimization Logic ---
def is_similar(a, b, threshold=0.6):
    """Check if two titles are similar using SequenceMatcher."""
    return difflib.SequenceMatcher(None, a, b).ratio() > threshold

def group_articles(articles):
    """Group similar articles together."""
    groups = []
    # articles must be sorted by date or score before grouping for best results
    # We assume they are already sorted.
    
    processed_indices = set()
    
    for i, article in enumerate(articles):
        if i in processed_indices:
            continue
            
        # Start a new group
        current_group = [article]
        processed_indices.add(i)
        
        # Look ahead for similar articles
        for j in range(i + 1, len(articles)):
            if j in processed_indices:
                continue
            
            other = articles[j]
            # Check similarity
            if is_similar(article['title'], other['title']):
                current_group.append(other)
                processed_indices.add(j)
        
        groups.append(current_group)
            
    return groups

def filter_muted_articles(articles, mute_words):
    """Filter out articles containing mute words."""
    if not mute_words:
        return articles
    
    filtered = []
    for item in articles:
        # Check title and summary
        text_to_check = (item['title'] + " " + item['summary']).lower()
        if not any(mw.lower() in text_to_check for mw in mute_words):
            filtered.append(item)
            
    return filtered


# --- Design ---
st.markdown(f"""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
    
    html, body, [data-testid="stAppViewContainer"] {{
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
        background-color: {c['bg']};
    }}
    
    header[data-testid="stHeader"] svg {{
        fill: #888888 !important;
        opacity: 0.8;
    }}
    header[data-testid="stHeader"] button {{
        color: #888888 !important;
    }}
    header[data-testid="stHeader"] {{ background-color: transparent !important; }}
    
    /* Requested Header Background Fix */
    .st-emotion-cache-14vh5up {{
        background-color: {c['bg']} !important;
    }}
    
    [data-testid="stMain"] {{
        color: {c['text']} !important;
    }}

    [data-testid="stSidebar"] {{
        background-color: {c['sidebar_bg']} !important;
        border-right: 1px solid {c['border']};
    }}
    
    /* Global Sidebar Text/Headings/Links */
    [data-testid="stSidebar"] p, 
    [data-testid="stSidebar"] label, 
    [data-testid="stSidebar"] h1, 
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3,
    [data-testid="stSidebar"] .stMarkdown,
    [data-testid="stSidebar"] [data-testid="stWidgetLabel"] {{
        color: {c['text']} !important;
        font-weight: 600 !important;
    }}
    
    /* Fix for Logged in / Links in sidebar */
    [data-testid="stSidebar"] a {{
        color: {c['sub_text']} !important;
        text-decoration: underline;
    }}

    /* Expander / Accordion Styling Fix */
    [data-testid="stSidebar"] [data-testid="stExpander"] {{
        border: 1px solid {c['border']} !important;
        border-radius: 8px !important;
        background-color: transparent !important;
    }}
    [data-testid="stSidebar"] [data-testid="stExpander"] summary {{
        background-color: transparent !important;
        color: {c['text']} !important;
    }}
    [data-testid="stSidebar"] [data-testid="stExpander"] summary:hover {{
        background-color: {c['input_bg']} !important;
    }}
    /* SVG icon in expander */
    [data-testid="stSidebar"] [data-testid="stExpander"] summary svg {{
        fill: {c['text']} !important;
    }}

    div[data-baseweb="select"] > div, div[data-baseweb="input"] > div {{
        background-color: {c['input_bg']} !important;
        border: 1px solid {c['border']} !important;
        border-radius: 8px !important;
    }}
    /* Ensure visible text color in selectboxes and inputs */
    div[data-baseweb="select"] [data-testid="stMarkdownContainer"] p,
    div[data-baseweb="select"] span,
    div[data-baseweb="select"] div,
    div[data-baseweb="input"] input {{
        color: {c['text']} !important;
        -webkit-text-fill-color: {c['text']} !important;
    }}
    /* Placeholder contrast */
    ::placeholder {{
        color: {c['sub_text']} !important;
        opacity: 0.8 !important;
    }}

    .news-item {{
        padding: 24px 0;
        border-bottom: 1px solid {c['border']};
        margin-bottom: 8px;
    }}
    
    .news-title-link {{
        text-decoration: none !important;
        color: {c['text']} !important;
        transition: opacity 0.2s ease;
    }}
    .news-title-link:hover {{ opacity: 0.7; }}
    
    .news-title {{
        font-size: 1.35rem; font-weight: 700; line-height: 1.4; margin-bottom: 12px; color: {c['text']};
    }}
    
    .news-excerpt {{
        font-size: 0.95rem; color: {c['sub_text']} !important; line-height: 1.6; margin-bottom: 16px;
        display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden;
    }}
    
    .news-meta {{
        font-size: 0.85rem; color: {c['sub_text']} !important; font-weight: 500; text-transform: uppercase; letter-spacing: 0.03em; margin-bottom: 12px;
    }}
    
    img.news-thumb {{
        width: 100%; aspect-ratio: 16/9; object-fit: cover;
        border-radius: 12px;
        margin-bottom: 16px;
        background-color: {c['border']};
        filter: brightness(0.85);
    }}
    
    .stButton > button {{
        background-color: {c['button_bg']} !important;
        color: {c['button_text']} !important;
        border: 1px solid {c['border']} !important;
        border-radius: 980px !important;
        font-weight: 600 !important;
        padding: 8px 16px !important;
        font-size: 0.9rem !important;
    }}
    .stButton > button:hover, .stButton > button:hover p {{ 
        background-color: {c['accent']} !important; 
        color: {c['bg']} !important; 
    }}

    .stTabs [data-baseweb="tab-list"] {{ gap: 40px; border-bottom: 1px solid {c['border']}; }}
    .stTabs [data-baseweb="tab"] {{ height: 60px; font-size: 1.2rem; color: {c['sub_text']}; font-weight: 700; }}
    .stTabs [aria-selected="true"] {{ color: {c['text']} !important; border-bottom-color: {c['text']} !important; }}
    
    .score-badge {{
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 0.85rem;
        font-weight: 600;
        margin-left: 8px;
        display: inline-block;
    }}
    
    /* Scroll to Top Button */
    #scroll-to-top {{
        position: fixed;
        bottom: 30px;
        left: 30px;
        width: 50px;
        height: 50px;
        background: linear-gradient(135deg, {c['accent']} 0%, {c['text']} 100%);
        color: {c['bg']};
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 24px;
        cursor: pointer;
        opacity: 0;
        visibility: hidden;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(0,0,0,0.3);
        z-index: 9999;
    }}
    
    #scroll-to-top.visible {{
        opacity: 1;
        visibility: visible;
    }}
    
    #scroll-to-top:hover {{
        transform: translateY(-5px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.4);
    }}
</style>
""", unsafe_allow_html=True)

# --- Login / Main Logic Switch ---

if 'guest_mode' not in st.session_state:
    st.session_state.guest_mode = False
if 'auth_step' not in st.session_state:
    st.session_state.auth_step = 'login' # login, 2fa, recovery_code, recovery_pass


if not st.session_state.user and not st.session_state.guest_mode:
    # --- Login/Register/Recovery UI ---
    st.markdown(f"""
        <style>
        .stApp {{ background-color: {c['bg']}; }}
        h1, h2, h3, label {{ color: {c['text']} !important; }}
        .stTextInput input {{ background-color: {c['input_bg']} !important; color: {c['text']} !important; }}
        </style>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown(f"<h1 style='text-align: center;'>ğŸŒ AI News Pro</h1>", unsafe_allow_html=True)
        
        # 2FA Verification Screen
        if st.session_state.auth_step == '2fa':
            st.markdown("### 2æ®µéšèªè¨¼")
            st.info(f"èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’ç™»éŒ²ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã«é€ä¿¡ã—ã¾ã—ãŸã€‚å—ä¿¡ãƒˆãƒ¬ã‚¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            code_input = st.text_input("èªè¨¼ã‚³ãƒ¼ãƒ‰", key="2fa_code")
            if st.button("èªè¨¼", use_container_width=True, type="primary"):
                if db.verify_2fa(st.session_state.temp_email, code_input):
                    email = st.session_state.temp_email
                    st.session_state.user = email
                    # Create persistent session with both URL and Cookie
                    ip = get_remote_ip()
                    set_persistent_login(email, ip)
                    
                    load_user_session()
                    clear_auth_flow()
                    st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.error("ã‚³ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
            if st.button("æˆ»ã‚‹", use_container_width=True):
                clear_auth_flow()
                st.rerun()

        # Recovery Code Screen
        elif st.session_state.auth_step == 'recovery_code':
            st.markdown("### ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å†è¨­å®š")
            st.info("èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¡ãƒ¼ãƒ«ã«é€ä¿¡ã—ã¾ã—ãŸã€‚å—ä¿¡ãƒˆãƒ¬ã‚¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            rec_code = st.text_input("èªè¨¼ã‚³ãƒ¼ãƒ‰", key="rec_code_input")
            if st.button("æ¬¡ã¸", use_container_width=True, type="primary"):
                if db.verify_recovery_code(st.session_state.temp_email, rec_code):
                    st.session_state.auth_step = 'recovery_pass'
                    st.rerun()
                else:
                    st.error("ã‚³ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
            if st.button("æˆ»ã‚‹"):
                clear_auth_state()
                st.rerun()

        # Recovery New Password Screen
        elif st.session_state.auth_step == 'recovery_pass':
            st.markdown("### æ–°ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰")
            new_p1 = st.text_input("æ–°ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="new_p1")
            new_p2 = st.text_input("ç¢ºèªç”¨", type="password", key="new_p2")
            if st.button("å¤‰æ›´", use_container_width=True, type="primary"):
                if new_p1 and new_p1 == new_p2:
                    db.update_password(st.session_state.temp_email, new_p1)
                    st.success("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¾ã—ãŸï¼ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                    clear_auth_state()
                    time.sleep(2)
                    st.rerun()
                else:
                    st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¾ã›ã‚“")

        # Main Auth Tabs (Login / Register / Forgot)
        else:
            tab_login, tab_register, tab_forgot = st.tabs(["ãƒ­ã‚°ã‚¤ãƒ³", "æ–°è¦ç™»éŒ²", "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¿˜ã‚Œ"])
            
            with tab_login:
                l_mail = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", key="l_mail")
                l_pass = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="l_pass")
                if st.button("ãƒ­ã‚°ã‚¤ãƒ³", use_container_width=True, type="primary"):
                    secret = db.verify_user(l_mail, l_pass)
                    if secret:
                        # Generate and send real code
                        code = db.set_auth_code(l_mail)
                        if send_auth_email(l_mail, "ã€AI News Proã€‘èªè¨¼ã‚³ãƒ¼ãƒ‰", f"ã‚ãªãŸã®èªè¨¼ã‚³ãƒ¼ãƒ‰ã¯ {code} ã§ã™ã€‚"):
                            st.session_state.temp_email = l_mail
                            st.session_state.temp_secret = secret
                            st.session_state.auth_step = '2fa'
                            st.rerun()
                        else:
                            st.error("ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        st.error("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
            
            with tab_register:
                r_mail = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", key="r_mail")
                r_pass = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="r_pass")
                if st.button("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ", use_container_width=True):
                    if r_mail and r_pass:
                        secret = db.create_user(r_mail, r_pass)
                        if secret:
                            # Generate and send code
                            code = db.set_auth_code(r_mail)
                            if send_auth_email(r_mail, "ã€AI News Proã€‘æ–°è¦ç™»éŒ² èªè¨¼ã‚³ãƒ¼ãƒ‰", f"æ–°è¦ç™»éŒ²ã‚’å®Œäº†ã™ã‚‹ãŸã‚ã®èªè¨¼ã‚³ãƒ¼ãƒ‰ã¯ {code} ã§ã™ã€‚"):
                                st.session_state.temp_email = r_mail
                                st.session_state.temp_secret = secret
                                st.session_state.auth_step = '2fa'
                                st.success("èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’é€ä¿¡ã—ã¾ã—ãŸï¼")
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.error("ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        else:
                            st.error("ãã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™")
                    else:
                        st.warning("å…¨ã¦ã®é …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

            with tab_forgot:
                f_mail = st.text_input("ç™»éŒ²ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", key="f_mail")
                if st.button("ã‚³ãƒ¼ãƒ‰é€ä¿¡", use_container_width=True):
                    if f_mail:
                        code = db.set_recovery_code(f_mail)
                        if code:
                            if send_auth_email(f_mail, "ã€AI News Proã€‘ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å†è¨­å®šã‚³ãƒ¼ãƒ‰", f"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å†è¨­å®šç”¨ã®èªè¨¼ã‚³ãƒ¼ãƒ‰ã¯ {code} ã§ã™ã€‚"):
                                st.session_state.temp_email = f_mail
                                st.session_state.auth_step = 'recovery_code'
                                st.rerun()
                            else:
                                st.error("ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        else:
                            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            st.divider()
            if st.button("ãƒ­ã‚°ã‚¤ãƒ³ã›ãšã«åˆ©ç”¨ã™ã‚‹ï¼ˆã‚²ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰", use_container_width=True):
                st.session_state.guest_mode = True
                st.session_state.user = None
                st.rerun()
    
    st.stop() # Stop execution here if not logged in


# --- Main Content ---
st.markdown(f"<h1>{source}</h1>", unsafe_allow_html=True)
st.markdown(f"<p style='color:{c['sub_text']}; font-size:1.3rem; font-weight:600; margin-top:-15px;'>{cat_label}</p>", unsafe_allow_html=True)

tab1, tab2, tab3, tab4 = st.tabs(["æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ãŠã™ã™ã‚", "ä¿å­˜æ¸ˆã¿", "æ¤œç´¢"])

with tab1:
    content_col = st.container()
    with content_col:
        c1, c2 = st.columns([1, 1])
        with c1: 
            if st.button("æ›´æ–°", use_container_width=True): st.rerun()
        with c2:
            if st.button("ğŸ–¼ï¸ å…¨ç”»åƒã‚’èª­ã¿è¾¼ã‚€", use_container_width=True):
                items = fetch_news(source, cat_code, "")
                for it in items:
                    ik = f"ic_{it['id']}"
                    if not it['img_src'] and ik not in st.session_state:
                        st.session_state[ik] = fetch_og_image(it['link'])
                st.rerun()

        with st.spinner("å–å¾—ä¸­..."):
            news_items = fetch_news(source, cat_code, "")
            
        if not news_items:
             st.info("ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
             # 1. Filter Mute Words
             filtered_items = filter_muted_articles(news_items, st.session_state.mute_words)
             
             if not filtered_items:
                 st.info("ã™ã¹ã¦ã®è¨˜äº‹ãŒãƒŸãƒ¥ãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸã€‚")
             else:
                 # 2. Smart Grouping
                 grouped_items = group_articles(filtered_items)
                 
                 st.markdown(f"**è¡¨ç¤ºä¸­: {len(filtered_items)} ä»¶ (ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ¸ˆ)**")
                 
                 cols = st.columns(3)
                 for i, group in enumerate(grouped_items):
                     # Show the first article as main
                     main_item = group[0]
                     related_count = len(group) - 1
                     
                     with cols[i % 3]:
                         st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                         ik = f"ic_{main_item['id']}"
                         img = main_item['img_src'] or st.session_state.get(ik)
                         
                         st.markdown(f'<div class="news-meta">{main_item["source"]} â€¢ {main_item["published"]}</div>', unsafe_allow_html=True)
                         if img: st.markdown(f'<a href="{main_item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                         st.markdown(f'<a href="{main_item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{main_item["title"]}</div></a>', unsafe_allow_html=True)
                         
                         if main_item['summary']:
                             st.markdown(f'<div class="news-excerpt">{main_item["summary"]}</div>', unsafe_allow_html=True)
                         
                         b1, b2 = st.columns(2)
                         with b1:
                              if not img:
                                 if st.button("ğŸ–¼ï¸ ç”»åƒ", key=f"img_{i}", use_container_width=True):
                                     st.session_state[ik] = fetch_og_image(main_item['link'])
                                     st.rerun()
                         with b2:
                             if st.button("ä¿å­˜ ğŸ”–", key=f"sav_{i}", use_container_width=True):
                                 existing = [b for b in st.session_state.bookmarks if b['link'] == main_item['link']]
                                 if existing:
                                     st.session_state.bookmarks = [b for b in st.session_state.bookmarks if b['link'] != main_item['link']]
                                     st.toast("ä¿å­˜ã‚’è§£é™¤ã—ã¾ã—ãŸ")
                                 else:
                                     st.session_state.bookmarks.append(main_item)
                                     st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                                 # Save Bookmark to DB
                                 if st.session_state.user:
                                     db.save_user_data(st.session_state.user, 'bookmarks', st.session_state.bookmarks)
                                 st.rerun()
                         
                         # Show Related Articles if any
                         if related_count > 0:
                             with st.expander(f"ä»– {related_count} ä»¶ã®é–¢é€£è¨˜äº‹"):
                                 for rel in group[1:]:
                                     st.markdown(f"- [{rel['source']}] [{rel['title']}]({rel['link']})")
                         
                         st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    if not st.session_state.recommendation_keywords:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒãŠã™ã™ã‚è¨­å®šã€ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç™»éŒ²ã™ã‚‹ã‹ã€ä¸‹ã®äººæ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ã€‚")
        
        # Popular keyword suggestions
        st.markdown("### ğŸ’¡ äººæ°—ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        popular_keywords = [
            "AI", "Python", "ChatGPT", "æ©Ÿæ¢°å­¦ç¿’", 
            "çµŒæ¸ˆ", "æ ªä¾¡", "å††ç›¸å ´", "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³",
            "iPhone", "Android", "Google", "Apple",
            "ã‚µãƒƒã‚«ãƒ¼", "é‡çƒ", "ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯",
            "æ˜ ç”»", "ã‚¢ãƒ‹ãƒ¡", "éŸ³æ¥½", "ã‚²ãƒ¼ãƒ "
        ]
        
        cols = st.columns(4)
        for i, kw in enumerate(popular_keywords):
            with cols[i % 4]:
                if st.button(f"â• {kw}", key=f"add_popular_{i}", use_container_width=True):
                    if kw not in st.session_state.recommendation_keywords:
                        st.session_state.recommendation_keywords.append(kw)
                        if st.session_state.user:
                            db.save_user_data(st.session_state.user, 'keywords', st.session_state.recommendation_keywords)
                        st.toast(f"ã€Œ{kw}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                        st.rerun()
    else:
        st.markdown(f"**ç™»éŒ²ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:** {', '.join(st.session_state.recommendation_keywords)}")
        
        with st.spinner("å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãŠã™ã™ã‚è¨˜äº‹ã‚’å–å¾—ä¸­..."):
            scored_items = get_recommended_articles(st.session_state.recommendation_keywords)
            
            # Filter by source if not ç·åˆãƒˆãƒƒãƒ—
            if source != "âš¡ ç·åˆãƒˆãƒƒãƒ—" and scored_items:
                scored_items = [(score, item) for score, item in scored_items if item['source'] == source]
            
            # Filter Mute Words
            if scored_items and st.session_state.mute_words:
                filtered_scored = []
                for score, item in scored_items:
                    text_check = (item['title'] + " " + item['summary']).lower()
                    if not any(mw.lower() in text_check for mw in st.session_state.mute_words):
                        filtered_scored.append((score, item))
                scored_items = filtered_scored
        
        if scored_items:
            # Default is already score order (from get_recommended_articles)
            
            # Limit display to top 50 AFTER filtering
            display_items = scored_items[:50]
            
            st.caption(f"å…¨ {len(scored_items)} ä»¶ä¸­ {len(display_items)} ä»¶ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™")

            # Bulk image load button
            if st.button("ğŸ–¼ï¸ å…¨ç”»åƒã‚’èª­ã¿è¾¼ã‚€", key="rec_load_all_images", use_container_width=True):
                for score, item in display_items:
                    ik = f"ic_{item['id']}"
                    if not item['img_src'] and ik not in st.session_state:
                         st.session_state[ik] = fetch_og_image(item['link'])
                st.rerun()
            
            # Load app icon for placeholder
            try:
                with open("app_icon.png", "rb") as f:
                    icon_b64 = base64.b64encode(f.read()).decode()
                placeholder_img = f"data:image/png;base64,{icon_b64}"
            except:
                placeholder_img = None

            cols = st.columns(3)
            for i, (score, item) in enumerate(display_items):
                with cols[i % 3]:
                    st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                    ik = f"ic_{item['id']}"
                    img = item['img_src'] or st.session_state.get(ik)
                    
                    if img:
                        st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                    elif placeholder_img:
                        st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{placeholder_img}" class="news-thumb" style="object-fit: contain; padding: 10px; background: #222;"></a>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="news-thumb" style="background:#333;display:flex;align-items:center;justify-content:center;font-size:3rem;">ğŸŒ</div>', unsafe_allow_html=True)
                    
                    # Display source and score
                    st.markdown(f'''
                        <div class="news-content">
                            <div class="news-meta">{item['source']} â€¢ {item['published'][:10]}
                            <span class="score-badge">ğŸ† {score}ç‚¹</span></div>
                            <a href="{item["link"]}" target="_blank" style="text-decoration:none;color:inherit;">
                                <div class="news-title">{item['title']}</div>
                            </a>
                            <div class="news-excerpt">{item['summary'][:60]}...</div>
                        </div>
                    ''', unsafe_allow_html=True)
                    
                    if st.button("ä¿å­˜ ğŸ”–", key=f"rec_sav_{i}", use_container_width=True):
                        if not any(b['link'] == item['link'] for b in st.session_state.bookmarks):
                            st.session_state.bookmarks.append(item)
                            st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                            # Save to DB
                            if st.session_state.user:
                                db.save_user_data(st.session_state.user, 'bookmarks', st.session_state.bookmarks)
                        else:
                            st.toast("æ—¢ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

with tab3:
    # Filter bookmarks by source if not ç·åˆãƒˆãƒƒãƒ—
    display_bookmarks = st.session_state.bookmarks
    if source != "âš¡ ç·åˆãƒˆãƒƒãƒ—":
        display_bookmarks = [b for b in st.session_state.bookmarks if b['source'] == source]
    
    if not display_bookmarks:
        if source == "âš¡ ç·åˆãƒˆãƒƒãƒ—":
            st.info("ä¿å­˜ã—ãŸè¨˜äº‹ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.info(f"{source} ã®ä¿å­˜æ¸ˆã¿è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # CSV Export button
        if st.button("ğŸ“¥ CSVã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", use_container_width=True):
            df = pd.DataFrame([{
                'ã‚¿ã‚¤ãƒˆãƒ«': b['title'],
                'URL': b['link'],
                'ã‚½ãƒ¼ã‚¹': b['source'],
                'æ—¥ä»˜': b['published'],
                'è¦ç´„': b['summary']
            } for b in display_bookmarks])
            
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="bookmarks.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        st.divider()
        
        cols_b = st.columns(3)
        for i, item in enumerate(display_bookmarks):
            with cols_b[i % 3]:
                st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                ik = f"ic_{item['id']}"
                img = item.get('img_src') or st.session_state.get(ik)
                
                st.markdown(f'<div class="news-meta">{item["source"]} â€¢ {item["published"]}</div>', unsafe_allow_html=True)
                if img: st.markdown(f'<a href="{item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                
                if item['summary']:
                    st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                
                if st.button("å‰Šé™¤ ğŸ—‘ï¸", key=f"del_{i}", use_container_width=True):
                    # Find and remove from original bookmarks list
                    st.session_state.bookmarks = [b for b in st.session_state.bookmarks if b['link'] != item['link']]
                    # Save to DB
                    if st.session_state.user:
                        db.save_user_data(st.session_state.user, 'bookmarks', st.session_state.bookmarks)
                    st.rerun()
                
                st.markdown('</div>', unsafe_allow_html=True)

with tab4:
    st.markdown("### å…¨ã‚½ãƒ¼ã‚¹æ¨ªæ–­æ¤œç´¢ ğŸ”")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        search_query = st.text_input("æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", placeholder="ä¾‹: ç”ŸæˆAI, åŠå°ä½“, é¸æŒ™", key="global_search_input")
    with col2:
        st.markdown("<div style='margin-top: 28px;'></div>", unsafe_allow_html=True)
        search_btn = st.button("æ¤œç´¢", use_container_width=True, type="primary")
        
    if search_query:
        with st.spinner(f"'{search_query}' ã§å…¨ã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­..."):
            results = get_search_results(search_query)
            
            filtered_results = results

            # Filter Mute Words
            search_final = filter_muted_articles(filtered_results, st.session_state.mute_words)
            
            st.markdown(f"**æ¤œç´¢çµæœ: {len(search_final)} ä»¶**")
            
            if not search_final:
                st.info("è©²å½“ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆã¾ãŸã¯ãƒŸãƒ¥ãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸï¼‰ã€‚")
            else:
                # Grouping
                search_grouped = group_articles(search_final)
                st.caption(f"(ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ¸ˆ)")
                
                cols = st.columns(3)
                for i, group in enumerate(search_grouped):
                    main_item = group[0]
                    related_count = len(group) - 1
                    
                    with cols[i % 3]:
                        st.markdown(f'<div class="news-item">', unsafe_allow_html=True)
                        ik = f"sic_{i}_{main_item['link']}" # unique key
                        img = main_item.get('img_src') or st.session_state.get(ik)
                        
                        st.markdown(f'<div class="news-meta">{main_item["source"]} â€¢ {main_item["published"]}</div>', unsafe_allow_html=True)
                        if img: st.markdown(f'<a href="{main_item["link"]}" target="_blank"><img src="{img}" class="news-thumb"></a>', unsafe_allow_html=True)
                        st.markdown(f'<a href="{main_item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{main_item["title"]}</div></a>', unsafe_allow_html=True)
                        
                        if main_item['summary']:
                            st.markdown(f'<div class="news-excerpt">{main_item["summary"]}</div>', unsafe_allow_html=True)
                        
                        b1, b2 = st.columns(2)
                        with b1:
                            if not img:
                                if st.button("ğŸ–¼ï¸ ç”»åƒ", key=f"s_img_{i}", use_container_width=True):
                                    st.session_state[ik] = fetch_og_image(main_item['link'])
                                    st.rerun()
                        with b2:
                            if st.button("ä¿å­˜ ğŸ”–", key=f"s_sav_{i}", use_container_width=True):
                                # Save logic
                                existing = [b for b in st.session_state.bookmarks if b['link'] == main_item['link']]
                                if existing:
                                    st.session_state.bookmarks = [b for b in st.session_state.bookmarks if b['link'] != main_item['link']]
                                    st.toast("ä¿å­˜ã‚’è§£é™¤ã—ã¾ã—ãŸ")
                                else:
                                    st.session_state.bookmarks.append(main_item)
                                    st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                                
                                if st.session_state.user:
                                    db.save_user_data(st.session_state.user, 'bookmarks', st.session_state.bookmarks)
                                st.rerun()
                        
                        # Show Related Search Results
                        if related_count > 0:
                            with st.expander(f"ä»– {related_count} ä»¶"):
                                for rel in group[1:]:
                                    st.markdown(f"- [{rel['source']}] [{rel['title']}]({rel['link']})")

                        st.markdown('</div>', unsafe_allow_html=True)
                        st.markdown(f'<a href="{item["link"]}" target="_blank" class="news-title-link"><div class="news-title">{item["title"]}</div></a>', unsafe_allow_html=True)
                        
                        if item['summary']:
                            st.markdown(f'<div class="news-excerpt">{item["summary"]}</div>', unsafe_allow_html=True)
                            
                        if st.button("ä¿å­˜ ğŸ”–", key=f"search_sav_{i}", use_container_width=True):
                            if not any(b['link'] == item['link'] for b in st.session_state.bookmarks):
                                st.session_state.bookmarks.append(item)
                                st.toast("ä¿å­˜ã—ã¾ã—ãŸ")
                                # Save to DB
                                if st.session_state.user:
                                    db.save_user_data(st.session_state.user, 'bookmarks', st.session_state.bookmarks)
                        
                
                st.markdown('</div>', unsafe_allow_html=True)
